#!/usr/bin/env python
# coding: utf-8

# This calculates read noise and gain of frames taken with the CRED2 camera

# Made from Dillon's parent notebook 2022 Aug 25 by E.S.

import os
from os import listdir
from os.path import isfile,join
import numpy as np
import matplotlib.pyplot as plt
import glob
from astropy.io import fits

## BEGIN USER INPUTS
stem = "/Users/bandari/Documents/git.repos/gpi2_misc/data/"
string_gain = "Low" # for printing and file paths
fps_flat = int(150) # integration time of flats to use (note that linearity and dark frames have several integration times)
## END USER INPUTS

path_gain_flats = stem + "test_frames_20221028/"+string_gain+"_Gain/Flats_("+str(fps_flat)+"_FPS)/"
path_gain_darks = stem + "test_frames_20221028/"+string_gain+"_Gain/Darks/"
path_gain_lin = stem + "test_frames_20221028/"+string_gain+"_Gain/Science_Images/"

flat_files = glob.glob(path_gain_flats + "*.raw")
dirs_darks_list = glob.glob(path_gain_darks + "*[0-9]")
darks_folders = [os.path.basename(i) for i in dirs_darks_list]

# sorted list of integration times
cadence_array = np.sort(np.array(darks_folders).astype(int))
exp_time_array = np.divide(1.,cadence_array)

# ## Creating Master Dark frames for each exposure time

# This code just runs through the files in each folder for the darks, and creates a master dark for each FPS

array_list_darks = []     # This is the final output of this block

# read noise: loop over integration times
print("---------------------------")
print("---- BEGIN READ NOISE -----")
noise_read_array = np.nan*np.ones(len(cadence_array))
print("Cadences (fps):",cadence_array)
for int_num in range(0,len(cadence_array)):

    print("FPS",cadence_array[int_num])

    folder_path = path_gain_lin + str(cadence_array[int_num]) # folders
    #filenames = [f for f in listdir(folder_path) if isfile(join(folder_path, f))]
    filenames = glob.glob(folder_path + "/*.raw")
    #print(filenames)

    temp_array_list = []

    # take 2 dark frames at a single integration time and find read noise
    for frames in filenames:

        img_file_0 = filenames[0]
        img_file_1 = filenames[1]
        arraytype_0 = np.fromfile(img_file_0, dtype = np.int16)
        arraytype_1 = np.fromfile(img_file_1, dtype = np.int16)
        #arraytype_0.shape = (512, 640)
        #arraytype_1.shape = (512, 640)
        arraytype_0.shape = (512, 18)
        arraytype_1.shape = (512, 18)

        # subtract and remove some of the edges
        arraytype_diff = np.subtract(arraytype_0[200:400,5:-6],arraytype_1[200:400,5:-6])

        noise_read = np.divide( np.std(arraytype_diff), np.sqrt(2) )

    noise_read_array[int_num] = noise_read


    '''
    # stdevs and mean/median of frames at given integration time
    std_dark = np.std(temp_array_list, axis = 0)
    mean_dark = np.mean(temp_array_list, axis = 0)    #Can change this to median if wanted

    # add net frame to stack of darks
    array_list_darks.append(mean_dark)
    '''

print("-----")
print("Read noise [ADU] for gain ", string_gain)
print("Mean:",np.mean(noise_read_array))
print("Std:",np.std(noise_read_array))

print("---- END READ NOISE -----")
print("---------------------------")


'''
# Read in cubes of dark-subtracted flats (which have not been normalized) and find gain
# (one cube per integration time; note cubes are generated by CRED2_analysis_eckhart.ipynb)

dir_flat_subt = "/Users/bandari/Documents/git.repos/gpi2_misc/notebooks_for_development/"

file_names_flat_subt_cube = glob.glob(dir_flat_subt + "junk_flat_subt_*fits")

# loop over cubes (one cube per integration time) and find gain
print("---------------------")
print("------- GAIN --------")
for flat_cube_num in range(0,len(file_names_flat_subt_cube)):

    print("----------------")
    print("Opening",file_names_flat_subt_cube[flat_cube_num])
    hdul = fits.open(file_names_flat_subt_cube[flat_cube_num])

    cube = hdul[0].data
    print("shape:",np.shape(cube))

    # avg of each slice
    avg_flats_array = np.mean(np.mean(cube, axis=1), axis=1)

    std_flats_array = np.nan*np.ones(np.shape(cube)[0])
    # loop over slices to get stdev of each 2D slice
    for slice_num in range(0,np.shape(cube)[0]):
        std_flats_array[slice_num] = np.std(cube[slice_num])

    # gain for this integration time
    # Gain = avg_flat/(sigma_adu^2)  [ADU^(-1)]
    gain_array = np.divide(avg_flats_array,np.power(std_flats_array,2.))
    print("-----")
    print("Gain [ADU^-1] for file",os.path.basename(file_names_flat_subt_cube[flat_cube_num]))
    print("Mean:",np.mean(gain_array))
    print("Std:",np.std(gain_array))
    print("... based on num of slices:",len(avg_flats_array))
'''

# We now have array_list_darks, which is a list of master dark arrays from 35 to 225 FPS (20) created by MEAN
# A quick look at one of the darks

'''
dark_plot = plt.figure()
dark_plot.add_axes()
plt.title('Dark for Low-Gain Darks [11]')
plt.xlabel('Columns')
plt.ylabel('Rows')
dark_plot = plt.imshow(array_list_darks[11], cmap = 'viridis', interpolation = 'nearest', origin="lower")
plt.colorbar(dark_plot)
plt.clim(400, 1200)

plt.show(dark_plot)
print (np.mean(array_list_darks[11]))
print (np.std(array_list_darks[11]))

#They really all look the same
'''


# In[11]:

'''
# save as 3D FITS file
#hdu = fits.PrimaryHDU(temp_array_list)
hdu = fits.PrimaryHDU(array_list_darks)
hdul = fits.HDUList([hdu])
hdul.writeto('junk_darks_3d.fits', overwrite=True)


# In[10]:


array_list_darks[3]


# ## Creating the Master Flat for 65 FPS

# In[12]:


#This code just creates a master flat (dark subtracted), and then normalizes it
master_flat_array = []

# loop over all flats at 65 FPS
for frames in flat_files:

    img_file = frames
    arraytype = np.fromfile(img_file, dtype = np.int16)
    arraytype.shape = (512, 640)

    # subtract dark
    arraytype = np.subtract(arraytype,array_list_darks[3])        #Subtracting the darks of the corresponding FPS (65)
    master_flat_array.append(arraytype)

# average the dark-subtracted flats
master_flat = np.mean(master_flat_array, axis = 0)     #Can change this to MEDIAN if wanted
master_flat = np.divide(master_flat,np.mean(master_flat))
# We now have a master flat frame, with darks subtracted and then AVERAGED

flat_plot = plt.figure()
flat_plot.add_axes()
plt.title('Master Flat for Low Gain')
plt.xlabel('Columns')
plt.ylabel('Rows')
flat_plot = plt.imshow(master_flat, cmap = 'viridis', interpolation = 'nearest')
plt.colorbar(flat_plot)
plt.clim(0.8, 1.2)

plt.show(flat_plot)
print (np.mean(master_flat))
print (np.std(master_flat))


# In[13]:


# save net frame as 3D FITS file

hdu = fits.PrimaryHDU(master_flat_array)
hdul = fits.HDUList([hdu])
hdul.writeto('junk_flat_3d.fits', overwrite=True)


# In[14]:


# save net frame as FITS file

hdu = fits.PrimaryHDU(master_flat)
hdul = fits.HDUList([hdu])
hdul.writeto('junk_flat.fits', overwrite=True)


# In[15]:


lin_folders


# ## Reducing the "Science" Images

# In[15]:


#This reduces the combined science images of each FPS with the darks of each respective FPS, and then divides by the
#master flat. It also records the mean and variances of each final science image to make a rudimentary gain plot

array_list_lin = []     # This is the final output of this block

mean_list = []
variance_list = []

# loop over integration times
for int_num in range(0,len(cadence_array)):

    folder_path = path_gain_lin + str(cadence_array[int_num]) # folders
    filenames = [f for f in listdir(folder_path) if isfile(join(folder_path, f))]
    print(filenames)
    print(cadence_array[int_num])

    temp_array_list = []

    # loop over 'science' frames at this integration time
    for frames in filenames:

        img_file = folder_path + '/' + frames
        arraytype = np.fromfile(img_file, dtype = np.int16)
        arraytype.shape = (512, 640)
        temp_array_list.append(arraytype)

    # save cube of frames at this integration time to check
    hdu = fits.PrimaryHDU(temp_array_list)
    hdul = fits.HDUList([hdu])
    hdul.writeto("junk_"+str(cadence_array[int_num])+".fits", overwrite=True)

    # make net frame for this integration time
    mean_lin = np.mean(temp_array_list, axis = 0)    #Can change this to median if wanted

    #Doing the reduction in this step, replacing divide by 0s with 0s

    # subtract dark
    sci_minus_dark = np.subtract(mean_lin,array_list_darks[int_num])
    # divide by flat
    final_lin = np.divide(sci_minus_dark, master_flat)

    idx_finite = np.isfinite(final_lin)
    mean_list.append(np.nanmean(final_lin[idx_finite]))
    variance_list.append(np.power(np.nanstd(final_lin[idx_finite]),2.0))

    # stack together frames at different integration times
    array_list_lin.append(final_lin)


# In[79]:


mean_list


# In[85]:


plt.xlabel("Integration time")
plt.ylabel("Counts")
plt.plot(exp_time_array,variance_list,label="variance")
plt.plot(exp_time_array,mean_list,label="mean")
plt.legend()
plt.savefig("test_plot.pdf")


# In[81]:


# save as 3D FITS file
#hdu = fits.PrimaryHDU(temp_array_list)
hdu = fits.PrimaryHDU(array_list_lin)
hdul = fits.HDUList([hdu])
hdul.writeto('junk.fits', overwrite=True)


# In[49]:


plt.scatter(exp_time_array, variance_list)


# In[81]:


#Calculates a linear fit for the slope
equation_fit = np.polyfit(mean_list, variance_list, 1)
print (equation_fit)

print ('The gain is the inverse of the slope, which gives us ' + str(1.0 / equation_fit[0]))


# In[82]:


#Just looking at one of the science images (reduced)
lin_plot = plt.figure()
lin_plot.add_axes()
plt.title('Science for Low Gain [1]')
plt.xlabel('Columns')
plt.ylabel('Rows')
lin_plot = plt.imshow(array_list_lin[0], cmap = 'viridis', interpolation = 'nearest')
plt.colorbar(lin_plot)
plt.clim(13500, 14500)

plt.show(lin_plot)
'''

# In[ ]:
